============================================
   Environment Variables Configuration
============================================

Create a file named ".env" in the backend directory.

============================================
AI PROVIDER CONFIGURATION
============================================

AI_PROVIDER=demo
  - Options: "demo", "ollama", "groq", "openai"
  - Default: "demo" (no API key required)

--------------------------------------------
OPTION 1: Demo Mode (Default, Free)
--------------------------------------------
AI_PROVIDER=demo

  - No API key required
  - Semantic search works normally
  - AI responses are simulated with instructions
  - Great for testing the UI and workflow

--------------------------------------------
OPTION 2: Ollama (Free, Runs Locally)
--------------------------------------------
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434

  - 100% free, runs on your machine
  - No data sent to external services
  - Requires Ollama installed:
    
    macOS:   brew install ollama
    Windows: Download from ollama.ai
    Linux:   curl -fsSL https://ollama.ai/install.sh | sh

  - Start Ollama and pull models:
    
    ollama serve
    ollama pull llama3.2
    ollama pull nomic-embed-text

--------------------------------------------
OPTION 3: Groq (Free Tier Available)
--------------------------------------------
AI_PROVIDER=groq
GROQ_API_KEY=gsk_your_groq_api_key_here

  - Very fast inference (100+ tokens/sec)
  - Free tier: 14,400 requests/day
  - Get API key: https://console.groq.com
  - Uses simple embeddings (no embedding API)

--------------------------------------------
OPTION 4: OpenAI (Paid, Best Quality)
--------------------------------------------
AI_PROVIDER=openai
OPENAI_API_KEY=sk-your_openai_api_key_here

  - Best quality responses
  - Best embeddings (text-embedding-3-small)
  - Requires paid API key
  - Get API key: https://platform.openai.com/api-keys

============================================
SERVER CONFIGURATION (Optional)
============================================

PORT=3000
  - Server port (default: 3000)

MAX_FILE_SIZE=100000000
  - Maximum upload file size in bytes (default: 100MB)

============================================
EXAMPLE .env FILES
============================================

--- Demo Mode (Default) ---
AI_PROVIDER=demo
PORT=3000

--- Ollama (Free, Local) ---
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
PORT=3000

--- Groq (Free Tier) ---
AI_PROVIDER=groq
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxx
PORT=3000

--- OpenAI ---
AI_PROVIDER=openai
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxx
PORT=3000

============================================
